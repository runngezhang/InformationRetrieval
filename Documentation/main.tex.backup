%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% University Assignment Title Page 
% LaTeX Template
% Version 1.0 (27/12/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% WikiBooks (http://en.wikibooks.org/wiki/LaTeX/Title_Creation)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
% 
% Instructions for using this template:
% This title page is capable of being compiled as is. This is not useful for 
% including it in another document. To do this, you have two options: 
%
% 1) Copy/paste everything between \begin{document} and \end{document} 
% starting at \begin{titlepage} and paste this into another LaTeX file where you 
% want your title page.
% OR
% 2) Remove everything outside the \begin{titlepage} and \end{titlepage} and 
% move this file to the same directory as the LaTeX file you wish to add it to. 
% Then add \input{./title_page_1.tex} to your LaTeX file where you want your
% title page.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\title{Title page with logo}
%----------------------------------------------------------------------------------------
%   PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{commath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{placeins}
\usepackage[round]{natbib}

\begin{document}


\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page

%----------------------------------------------------------------------------------------
%   HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE Aalto University}\\[1.5cm] % Name of your university/college
\textsc{\Large T-75.4400 Information retrieval}\\[0.5cm] % Major heading such as course name
\textsc{\large Assignment 2}\\[0.5cm] % Minor heading such as course title

%----------------------------------------------------------------------------------------
%   TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries On the Efficacy of Alternate Similary Measures, Stemming and Stop Word Removal in 
Text-Based Information Retrieval Systems}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%   AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.45\textwidth}
\begin{center} \large
\textsc{Antti Partanen}\\ % Your name
\texttt{antti.partanen@aalto.fi}\\
295967
\end{center}
\end{minipage}
~
\begin{minipage}{0.45\textwidth}
\begin{center} \large
\textsc{Vikram Kamath}\\ % Supervisor's Name
\texttt{vikram.kamath@aalto.fi}\\
440819
\end{center}
\end{minipage}\\[2cm]


% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name



%----------------------------------------------------------------------------------------
%   LOGO SECTION
%----------------------------------------------------------------------------------------

\includegraphics{AaltoSCI_EN_9.pdf}\\[1cm] % Include a department/university logo - this will require the graphicx package
 
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
%   DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise
\vfill % Fill the rest of the page with whitespace



\end{titlepage}

%\todo[inline, color=green!40]{Too messy titlepage?}

%\begin{abstract}
%In this paper, we compare compare two ranking methods: VSM (Vector Space Model) and BM25 for document collection from ACM digital library database. Furthermore, we study the effects of morphological techniques, including stemmers and stop words.
%\todo[inline, color=green!40]{Abstract maybe not necessary? Overlap with introduction?}
%\end{abstract}

\section{Introduction}

The task of Information retrieval is to obtain information resources relevant to the imminent need from information resources. Resources include books, journals and other documents. Searches can be based on meta-data or on full-text indexing.

Automated information retrieval systems are used to reduce the so called \textit{information overload}, i.e. the difficulty of a person to understand an issue due to overwhelming amounts of information. Most existing text retrieval techniques rely on indexing key-words. Unfortunately keywords or index terms alone cannot adequately capture the document contents, resulting in poor retrieval performance. Yet, keyword indexing is widely used in commercial systems because it is still the most viable way by far to process large amount of text. 

The generic textual information retrieval process is show in Figure \ref{fig:IR} and it has the following steps:
\begin{enumerate}
  \item The system builds and index of the documents (\textit{indexing}) 
  \item User describes the \textit{information need} in a form of a query, which is parsed and transformed by the system with the same operations applied to the documents (\textit{query formulation})
  \item The system retrieves, ranks and displays documents that are relevant to the query from the index
  \item User may give relevance feedback to the system
\end{enumerate}
\begin{figure}[ht]
	\centering
	\includegraphics[width=0.5\textwidth]{IR.png}
	\caption{Information retrieval pipeline \citep{hiemstra2009information}}
	\label{fig:IR}
\end{figure}
\FloatBarrier

Efficient and effective information retrieval techniques are critical in managing the increased amount of textual information available in electronic form. Therefore, it is no wonder that currently the most visible IR systems are web search engines.  

\textbf{Apache Lucene}

In this paper, we compare the two information retrieval techniques: Vector Space Model (VSM) and BM25. Furthermore, we analyze what effects does the usage of stemmers (porter stemmer) and stopwords have with the retrieval result. The evaluation of our experiments is visualized with eleven point precision recall curves. 

\todo[inline, color=green!40]{Draft version: aka needs modifying + references}

\section{Techniques}

Ranking methods are used by search engines to rank matching documents according to their relevance to a given search query. Most common approaches to information retrieval are algebraic (e.g. VSM) and probabilistic (e.g. BM25)

\subsection{VSM}

VSM (Vector Space Model) is an algebraic representation model for objects as vectors of identifiers. Beyond information retrieval, VSM is also used in information filtering and indexing. It was first introduced by \citep{ref1} and it was first utilized in SMART IR system \citep{ref2}.

The core idea of VSM is rather simple: represent documents ($D_j$) and queries ($Q$) as vectors in vector-space. 

\begin{center}
$ D_j = (w_{1,j}, w_{2,j},...,w_{t,j}) $ \\
$ Q = (w_{1,q}, w_{2,q},...,w_{n,q}) $
\end{center}

There are several different ways of calculating these weights, but \textit{tf-idf} is one on the best known. Documents are ranked according to their proximity to the query in this space, where proximity corresponds to the similarity of the vectors. Similarity is not calculated as an euclidean distance, but rather as an angle or cosine between the vectors

\begin{center}
$ cos\theta = \frac{D_j \cdot Q}{\norm{D_j} \norm{Q}} $ 
\end{center} 
, where the norm or length $ \norm{Q}$ is calculated as
\begin{center}
$ \norm{Q} = \sqrt{\sum\limits_{i=1}^n q_i } $ .
\end{center}

%The closer a document vector is to the query vector the higher ranking it receives.

\subsection{BM25}

BM25, often referred to as Okapi BM25 (where BM stands for Best Matching), is a probabilistic ranking function. It is based on probabilistic relevance model, devised by Robertson et al. \ref{ref3}.
BM25 uses a bag-of-words representation of a document, a representation that ignores the relative ordering
of words in the document and the query. It isn't one stand-alone method, but is actually a collection
of functions, each of which uses different hyperparameters, the outputs of which are combined to 
give the final similarity score between a document and a query. BM25 uses both term frequencies and
inverse document frequencies to compute the final similarity score. [TODO Insert Citation to Text book]


\todo[inline, color=green!40]{ADD REFERENCES}


\subsection{Stemmers}
In most languages and predominantly so in English, words occur in dif-
ferent forms even though they have the same meaning. For example
\lq democracy', \lq democratic' , \lq democratize' all have the same deriva-
tion and although they’re used in different contexts, they have the same
\lq semantic' meaning. More often than not, it would be useful to search for
using just one of the forms and have documents retrieved that con-
tain all semantically similar forms.
Lemmatization is a crude heuristic process that aims to achieve this by
removing the ends of the words so that different forms of the same word,
after processing, lead to the same, shortened form. So in the example
above, all three words would map to ’democraci’ after processing.
We used the porter stemmer [TODO: Insert Citation] for our experiments (although there ex-
ist many other different stemming algorithms that aim to achieve a good
’lemmatization’)
\subsection{Stopwords}
Most search engines preprocess both indexed text and search queries so as to
remove commonly occurring words that are of little value to the context
of the document. Words like \lq A', \lq and',\lq the', \lq of' etc are found abundantly in
most English documents but add no overall value to the indexing, ranking
or retrieval process. The average size of stopword collections is between
200 - 300 terms [TODO: Insert Citation].
We experimented with using the Lucene in-built stopword list, which although
not exhaustive (relative to some of the stop-word corpora available), is 
sufficiently good. 

\section{Evaluation}

\todo[inline, color=green!40]{Add text and charts}
\textbf{Precision}

\textbf{Recall}

\textbf{Eleven point precision recall curve}


\section{Conclusions}

\todo[inline, color=green!40]{Add conclusions}

\section{Contributions}
In the end both of us put equal amounts of effort into the project. 
We used GitHub [TODO: Citation?] for version control and although we did
some independent work at the comfort of our own homes, a bulk of the work
was done in a series of \lq hackathon' style, caffeine-fueled meetings, where we just sat
for 4-6 hours straight at Maari and woked on it. Although this style might be deemed by some
as a sloppy, we'd like to think of it as pair programming on speed - in that 
the fact that we sat together and worked on it enabled almost seamless debugging
and ideation.\\
A diagrammatic (albeit) rough division of tasks is shown below [TODO: Should we add this?]
\todo[inline, color=green!40]{Mind map style of work division might look neat?}

\begin{figure}[p]
    \centering
    \includegraphics[scale=0.6]{contributions_tree.pdf}
    \caption{Contributions represented in a mindmap}
    \label{fig:contributions_tree}
\end{figure}
\FloatBarrier

%\begin{figure}[h]


\nocite{*}
\bibliographystyle{plainnat}
\bibliography{bibliography.bib}

\todo[inline, color=green!40]{Add more references}

\appendix
\section{Installation instructions} \label{App:instructions}


Here is a brief systems installation and system configuration instructions. 

\begin{enumerate}

\item ...
\item ...

\end{enumerate}

\end{document}